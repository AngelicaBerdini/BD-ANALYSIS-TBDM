{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1337131,
          "sourceType": "datasetVersion",
          "datasetId": 776642
        },
        {
          "sourceId": 1337140,
          "sourceType": "datasetVersion",
          "datasetId": 776647
        },
        {
          "sourceId": 3316532,
          "sourceType": "datasetVersion",
          "datasetId": 10100
        }
      ],
      "dockerImageVersionId": 29980,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "ALS Model in PySpark",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelicaBerdini/BD-ANALYSIS-TBDM/blob/main/PySparkNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kaggle notebook\n",
        "This first cell was created only to download in memory the dataset from Kaggle.\n",
        "The datasets can't be loaded into the repository since they are too big."
      ],
      "metadata": {
        "id": "W5moZ4Ry2srf"
      }
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'yelp-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F10100%2F3316532%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240216%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240216T165350Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2890be448eecc5dc7b087e1ee28d020cf55288c9672161b184b3367da1075ed4c43869fdfcd5a9a2c725b970d6c234e9f320f64ffcaf3fc5da2f720ba80253bf8a93a3ce7a0339458b3ca44bd8ebc1be59432532cdd57ac07eb6e2f994237e412121e21624192fd80fa2fa2273ee7eafee65545929055f0e61a7f010f71a3649890f84bdcc68af98f1cd0f0240ef208d0529dd47fd4b49d7dc7c9b93cb4fea056cdaa1c65823587ba31cb43fec8ee857c91c7e0d44c391f7dd699afba73ff9b818f76076cbd8cf1793f5460d45c3c6add1da021d02e78e4d391169f1c3ff422409e4ebfeadc967f44f5a38fd26ff41ef923114f2701945fd78316b8e3a5493f4'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUZrmyfX1sLx",
        "outputId": "8201b4c9-9b7c-4fa9-cd96-5339c7ada704"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yelp-dataset, 4374983563 bytes compressed\n",
            "[==================================================] 4374983563 bytes downloaded\n",
            "Downloaded and uncompressed: yelp-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Section\n",
        "This section is used only in the case a different file from the following *PySparkNotebook.ipynb* has been modified.\n",
        "- The first cell is used to clone the repository.\n",
        "Execute it only if it's needed access to another element of the repository.\n",
        "- The second cell is used to pull changes from the repository in case there are.\n",
        "- The third should be executed only in the case there has been some changes on other files other than the current one. (Remember to modify the message of the commit)\n",
        "\n",
        "If this file was opened from GitHub and you need to save only the current notebook, just follow these steps from the menu of Colab:\n",
        "- File / Save a copy in GitHub.\n",
        "\n",
        "If instead, in the process, other files of the repository were needed and were also modified, use the cells below."
      ],
      "metadata": {
        "id": "nTIJtu2k2-Dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/AngelicaBerdini/BD-ANALYSIS-TBDM.git repository\n",
        "%cd repository\n",
        "!ls"
      ],
      "metadata": {
        "id": "Km8cxcjH3uPX",
        "outputId": "29023390-9ba9-4330-a139-ed0b7c97f8eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'repository' already exists and is not an empty directory.\n",
            "/content/repository\n",
            "PySparkNotebook.ipynb  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull all changes in case there has been some in the middle that hasn't been updated\n",
        "!git pull"
      ],
      "metadata": {
        "id": "-wU6S4_b362a",
        "outputId": "d08ceff8-c8cb-49f5-a382-d00b39d56e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import requests\n",
        "gcloud_token = !gcloud auth print-access-token\n",
        "gcloud_tokeninfo = requests.get('https://www.googleapis.com/oauth2/v3/tokeninfo?access_token=' + gcloud_token[0]).json()\n",
        "EMAIL = str(gcloud_tokeninfo['email'])\n",
        "\n",
        "!echo $EMAIL\n",
        "\n",
        "#Usare per fare commit atomici e frequenti.\n",
        "#Ricordiamoci di usare mettere sempre dei messaggi di commit chiari in modo da\n",
        "#poter rollbackare o cherry-pickare in caso di bisogno.\n",
        "\n",
        "!git config --global user.email $EMAIL\n",
        "\n",
        "!git add .\n",
        "# Change the message below between quotes \"...\" to modify the commit message\n",
        "!git commit -m \"Modifying repo structure\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "zYrV94FH4C-g",
        "outputId": "7f6d5532-2f1f-45bf-bda4-6cc68c46bc1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "luca.bianchi@studenti.unicam.it\n",
            "[main 8f66223] Modifying repo structure\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " rename PySparkNotebook.ipynb => PySparkNotebooks/PySparkNotebook.ipynb (100%)\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender system using Pyspark (ALS algorithm)\n",
        "---\n",
        "\n",
        "\n",
        "#### Requirements:\n",
        "- Python\n",
        "- Apache Spark\n",
        "\n",
        "## Import Libraries and Initialize spark session"
      ],
      "metadata": {
        "id": "epNYwpDR1sL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:46:41.053841Z",
          "iopub.execute_input": "2024-02-16T16:46:41.054256Z",
          "iopub.status.idle": "2024-02-16T16:47:39.073081Z",
          "shell.execute_reply.started": "2024-02-16T16:46:41.054209Z",
          "shell.execute_reply": "2024-02-16T16:47:39.07198Z"
        },
        "trusted": true,
        "id": "-Ao570W21sL2",
        "outputId": "84a497de-112e-46aa-9904-e4ca91cc85d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting pyspark\n  Downloading pyspark-3.4.2.tar.gz (311.1 MB)\n\u001b[K     |████████████████████████████████| 311.1 MB 19 kB/s  eta 0:00:013  |▋                               | 6.3 MB 2.6 MB/s eta 0:01:56     |██████████████████▏             | 177.1 MB 455 kB/s eta 0:04:551 MB 513 kB/s eta 0:00:22\n\u001b[?25hCollecting py4j==0.10.9.7\n  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n\u001b[K     |████████████████████████████████| 200 kB 38.9 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.2-py2.py3-none-any.whl size=311619856 sha256=ef22669d039a726f2baf1a489e61a36b4b49b88c684150573d28392ac2741aaa\n  Stored in directory: /root/.cache/pip/wheels/c3/8a/ac/cd39777597318310141c8a783c06f516815a66194f100f96b6\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9.7 pyspark-3.4.2\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "from pyspark import SparkContext\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import SparkSession ,Row\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.sql.types import StructType,StructField,IntegerType\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:47:39.075521Z",
          "iopub.execute_input": "2024-02-16T16:47:39.075886Z",
          "iopub.status.idle": "2024-02-16T16:47:39.530901Z",
          "shell.execute_reply.started": "2024-02-16T16:47:39.075849Z",
          "shell.execute_reply": "2024-02-16T16:47:39.529797Z"
        },
        "trusted": true,
        "id": "TxCkc3Uv1sL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "appName=\"Analysis Application with PySpark\"\n",
        "\n",
        "#initialize the spark session\n",
        "spark = SparkSession.builder.appName(appName).getOrCreate()\n",
        "\n",
        "#get sparkcontext from the sparksession\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:49:54.000999Z",
          "iopub.execute_input": "2024-02-16T16:49:54.001446Z",
          "iopub.status.idle": "2024-02-16T16:49:55.20774Z",
          "shell.execute_reply.started": "2024-02-16T16:49:54.001403Z",
          "shell.execute_reply": "2024-02-16T16:49:55.206621Z"
        },
        "trusted": true,
        "id": "MR8aUqyX1sL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset in Apache Spark\n"
      ],
      "metadata": {
        "id": "dEIgLyLt1sL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to data type the date of the review\n",
        "df_business = sqlContext.read.json('/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json')\n",
        "df_review = sqlContext.read.json('/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json')\n",
        "df_user = sqlContext.read.json('/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:50:00.322302Z",
          "iopub.execute_input": "2024-02-16T16:50:00.323127Z",
          "iopub.status.idle": "2024-02-16T16:51:30.148361Z",
          "shell.execute_reply.started": "2024-02-16T16:50:00.323064Z",
          "shell.execute_reply": "2024-02-16T16:51:30.147369Z"
        },
        "trusted": true,
        "id": "KOaV9Qj91sL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "YMMdRv5y1sL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataframe Business"
      ],
      "metadata": {
        "id": "SCEboVFB1sL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_business.printSchema()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:51:53.507992Z",
          "iopub.execute_input": "2024-02-16T16:51:53.508448Z",
          "iopub.status.idle": "2024-02-16T16:51:53.543913Z",
          "shell.execute_reply.started": "2024-02-16T16:51:53.508392Z",
          "shell.execute_reply": "2024-02-16T16:51:53.54284Z"
        },
        "trusted": true,
        "id": "xSkhHvEX1sL9",
        "outputId": "5021f08e-44c8-4cbf-f68c-2196e59df28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "root\n |-- address: string (nullable = true)\n |-- attributes: struct (nullable = true)\n |    |-- AcceptsInsurance: string (nullable = true)\n |    |-- AgesAllowed: string (nullable = true)\n |    |-- Alcohol: string (nullable = true)\n |    |-- Ambience: string (nullable = true)\n |    |-- BYOB: string (nullable = true)\n |    |-- BYOBCorkage: string (nullable = true)\n |    |-- BestNights: string (nullable = true)\n |    |-- BikeParking: string (nullable = true)\n |    |-- BusinessAcceptsBitcoin: string (nullable = true)\n |    |-- BusinessAcceptsCreditCards: string (nullable = true)\n |    |-- BusinessParking: string (nullable = true)\n |    |-- ByAppointmentOnly: string (nullable = true)\n |    |-- Caters: string (nullable = true)\n |    |-- CoatCheck: string (nullable = true)\n |    |-- Corkage: string (nullable = true)\n |    |-- DietaryRestrictions: string (nullable = true)\n |    |-- DogsAllowed: string (nullable = true)\n |    |-- DriveThru: string (nullable = true)\n |    |-- GoodForDancing: string (nullable = true)\n |    |-- GoodForKids: string (nullable = true)\n |    |-- GoodForMeal: string (nullable = true)\n |    |-- HairSpecializesIn: string (nullable = true)\n |    |-- HappyHour: string (nullable = true)\n |    |-- HasTV: string (nullable = true)\n |    |-- Music: string (nullable = true)\n |    |-- NoiseLevel: string (nullable = true)\n |    |-- Open24Hours: string (nullable = true)\n |    |-- OutdoorSeating: string (nullable = true)\n |    |-- RestaurantsAttire: string (nullable = true)\n |    |-- RestaurantsCounterService: string (nullable = true)\n |    |-- RestaurantsDelivery: string (nullable = true)\n |    |-- RestaurantsGoodForGroups: string (nullable = true)\n |    |-- RestaurantsPriceRange2: string (nullable = true)\n |    |-- RestaurantsReservations: string (nullable = true)\n |    |-- RestaurantsTableService: string (nullable = true)\n |    |-- RestaurantsTakeOut: string (nullable = true)\n |    |-- Smoking: string (nullable = true)\n |    |-- WheelchairAccessible: string (nullable = true)\n |    |-- WiFi: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: string (nullable = true)\n |-- city: string (nullable = true)\n |-- hours: struct (nullable = true)\n |    |-- Friday: string (nullable = true)\n |    |-- Monday: string (nullable = true)\n |    |-- Saturday: string (nullable = true)\n |    |-- Sunday: string (nullable = true)\n |    |-- Thursday: string (nullable = true)\n |    |-- Tuesday: string (nullable = true)\n |    |-- Wednesday: string (nullable = true)\n |-- is_open: long (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- postal_code: string (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_business.select(\"business_id\").head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:53:12.212588Z",
          "iopub.execute_input": "2024-02-16T16:53:12.213427Z",
          "iopub.status.idle": "2024-02-16T16:53:12.778773Z",
          "shell.execute_reply.started": "2024-02-16T16:53:12.213362Z",
          "shell.execute_reply": "2024-02-16T16:53:12.777634Z"
        },
        "trusted": true,
        "id": "uVTJnCtR1sL_",
        "outputId": "3b9dcd8b-3592-4db8-d57f-991f73bd29c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[Row(business_id='Pns2l4eNsfO8kk83dixA6A'),\n Row(business_id='mpf3x-BjTdTEA3yCZrAYPw'),\n Row(business_id='tUFrWirKiKi_TAnsVWINQQ'),\n Row(business_id='MTSW4McQd7CbVtyjqoe9mw'),\n Row(business_id='mWMc6_wTdE0EUBKIGXDVfA'),\n Row(business_id='CF33F8-E6oudUQ46HnavjQ'),\n Row(business_id='n_0UpQx1hsNbnPUSlodU8w'),\n Row(business_id='qkRM_2X51Yqxk3btlwAQIg'),\n Row(business_id='k0hlBqXX-Bt0vf1op7Jr1w'),\n Row(business_id='bBDDEgkFA1Otx9Lfe7BZUQ')]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_business.dtypes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-16T16:52:52.493202Z",
          "iopub.execute_input": "2024-02-16T16:52:52.495007Z",
          "iopub.status.idle": "2024-02-16T16:52:52.589941Z",
          "shell.execute_reply.started": "2024-02-16T16:52:52.494922Z",
          "shell.execute_reply": "2024-02-16T16:52:52.588689Z"
        },
        "trusted": true,
        "id": "CU5N9MLZ1sL_",
        "outputId": "b469b04f-d940-4a18-d143-951c2e538ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[('address', 'string'),\n ('attributes',\n  'struct<AcceptsInsurance:string,AgesAllowed:string,Alcohol:string,Ambience:string,BYOB:string,BYOBCorkage:string,BestNights:string,BikeParking:string,BusinessAcceptsBitcoin:string,BusinessAcceptsCreditCards:string,BusinessParking:string,ByAppointmentOnly:string,Caters:string,CoatCheck:string,Corkage:string,DietaryRestrictions:string,DogsAllowed:string,DriveThru:string,GoodForDancing:string,GoodForKids:string,GoodForMeal:string,HairSpecializesIn:string,HappyHour:string,HasTV:string,Music:string,NoiseLevel:string,Open24Hours:string,OutdoorSeating:string,RestaurantsAttire:string,RestaurantsCounterService:string,RestaurantsDelivery:string,RestaurantsGoodForGroups:string,RestaurantsPriceRange2:string,RestaurantsReservations:string,RestaurantsTableService:string,RestaurantsTakeOut:string,Smoking:string,WheelchairAccessible:string,WiFi:string>'),\n ('business_id', 'string'),\n ('categories', 'string'),\n ('city', 'string'),\n ('hours',\n  'struct<Friday:string,Monday:string,Saturday:string,Sunday:string,Thursday:string,Tuesday:string,Wednesday:string>'),\n ('is_open', 'bigint'),\n ('latitude', 'double'),\n ('longitude', 'double'),\n ('name', 'string'),\n ('postal_code', 'string'),\n ('review_count', 'bigint'),\n ('stars', 'double'),\n ('state', 'string')]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using HuggingFace"
      ],
      "metadata": {
        "id": "iIGM4R-71sMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-10T11:55:59.437936Z",
          "iopub.execute_input": "2024-01-10T11:55:59.438271Z",
          "iopub.status.idle": "2024-01-10T11:56:09.242694Z",
          "shell.execute_reply.started": "2024-01-10T11:55:59.438238Z",
          "shell.execute_reply": "2024-01-10T11:56:09.240303Z"
        },
        "trusted": true,
        "id": "00bffGUJ1sMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-10T11:56:09.246651Z",
          "iopub.execute_input": "2024-01-10T11:56:09.247186Z",
          "iopub.status.idle": "2024-01-10T11:56:19.551071Z",
          "shell.execute_reply.started": "2024-01-10T11:56:09.247125Z",
          "shell.execute_reply": "2024-01-10T11:56:19.549868Z"
        },
        "trusted": true,
        "id": "TOd1rgf_1sMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-10T11:56:19.553014Z",
          "iopub.execute_input": "2024-01-10T11:56:19.55351Z",
          "iopub.status.idle": "2024-01-10T11:56:27.897671Z",
          "shell.execute_reply.started": "2024-01-10T11:56:19.553378Z",
          "shell.execute_reply": "2024-01-10T11:56:27.896286Z"
        },
        "trusted": true,
        "id": "fa3Fk5Re1sMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-10T12:00:17.045994Z",
          "iopub.execute_input": "2024-01-10T12:00:17.04648Z",
          "iopub.status.idle": "2024-01-10T12:00:23.379933Z",
          "shell.execute_reply.started": "2024-01-10T12:00:17.04644Z",
          "shell.execute_reply": "2024-01-10T12:00:23.378887Z"
        },
        "trusted": true,
        "id": "I_fS-C371sMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_review.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "W7d5kVNG1sMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_review.take(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-10T11:58:11.116003Z",
          "iopub.execute_input": "2024-01-10T11:58:11.116464Z",
          "iopub.status.idle": "2024-01-10T11:58:11.245708Z",
          "shell.execute_reply.started": "2024-01-10T11:58:11.116422Z",
          "shell.execute_reply": "2024-01-10T11:58:11.24409Z"
        },
        "trusted": true,
        "id": "DuhQTtHx1sMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier(df_review.select(\"text\").take(1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-01-10T11:50:29.314221Z",
          "iopub.execute_input": "2024-01-10T11:50:29.315146Z",
          "iopub.status.idle": "2024-01-10T11:50:29.575066Z",
          "shell.execute_reply.started": "2024-01-10T11:50:29.315089Z",
          "shell.execute_reply": "2024-01-10T11:50:29.573927Z"
        },
        "trusted": true,
        "id": "QhZIMz1J1sMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code already written in the notebook"
      ],
      "metadata": {
        "id": "aEW70e561sMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter Rows and columns\n",
        "\n"
      ],
      "metadata": {
        "id": "QloOQW9s1sMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_business = df_business.select(\"business_id\",\"name\", \"stars\",\n",
        "                                 \"review_count\", \"attributes\",\n",
        "                                 \"categories\", \"city\").withColumnRenamed(\"stars\", \"stars_restaurant\")\n",
        "\n",
        "df_business = df_business.filter((df_business['city'] == 'Toronto') & (df_business.categories.contains('Restaurants'))).drop('city')"
      ],
      "metadata": {
        "trusted": true,
        "id": "ry6e-J5m1sMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_review = df_review.join(df_business, on='business_id', how='inner')"
      ],
      "metadata": {
        "trusted": true,
        "id": "gxTA1FFO1sMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets make a quick visualisation to the basic elements of our review table."
      ],
      "metadata": {
        "id": "KfR_WXVA1sMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_review.select(['business_id', 'user_id', 'stars']).show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "nqN2svW71sMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "G8vyWfrz1sMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = df_review.select('stars').collect()\n",
        "review_list = [reviews[i][0] for i in range(len(reviews))]\n",
        "\n",
        "plt.hist(review_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5,\n",
        "         histtype='stepfilled', color='steelblue',\n",
        "         edgecolor='none')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Rating')\n",
        "plt.style.use('seaborn-white')"
      ],
      "metadata": {
        "trusted": true,
        "id": "PILaOwNv1sMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quite generous public from Toronto. Most ratings are above 3. Now lets see the the distrubtion of ratings of each restaurants."
      ],
      "metadata": {
        "id": "W8Ynbk2B1sMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_reviews = df_business.select('stars_restaurant').collect()\n",
        "restaurant_reviews_list = [restaurant_reviews[i][0] for i in range(len(restaurant_reviews))]\n",
        "\n",
        "\n",
        "plt.hist(restaurant_reviews_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5,\n",
        "         histtype='stepfilled', color='steelblue',\n",
        "         edgecolor='none')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Rating')\n",
        "plt.style.use('seaborn-white')"
      ],
      "metadata": {
        "trusted": true,
        "id": "cp8virW41sMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here were see a more normally distributed curve. Nevertheless most restaurants do pretty well.\n",
        "Now lets visualize what are the most popular type of restaurants in Toronto. What kind of food do they serve? We will create a wordcloud."
      ],
      "metadata": {
        "id": "m9YQV__N1sME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_categories = df_business.select('categories').collect()\n",
        "restaurant_categories_list = [restaurant_categories[i][0] for i in range(len(restaurant_categories))]"
      ],
      "metadata": {
        "trusted": true,
        "id": "KIcAfYrf1sME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(review for review in restaurant_categories_list)"
      ],
      "metadata": {
        "trusted": true,
        "id": "y5h447a21sME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "# eliminate useless words\n",
        "text = text.replace('Restaurants', \"\")\n",
        "text = text.replace('bars', \"\")\n",
        "text = text.replace('food', \"\")\n",
        "\n",
        "\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
        "\n",
        "# Display the generated image:\n",
        "# the matplotlib way:\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "B55JDbiA1sME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Convert String to index\n"
      ],
      "metadata": {
        "id": "jLq_mVAL1sME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in ['business_id', 'user_id']]\n",
        "pipeline = Pipeline(stages=indexer)\n",
        "transformed = pipeline.fit(df_review).transform(df_review)\n",
        "transformed.select(['business_id', 'user_id','business_id_index', 'user_id_index'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "Xr5ZT3se1sMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset in train and test\n"
      ],
      "metadata": {
        "id": "N6ky59cN1sMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(training, test) = transformed.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "trusted": true,
        "id": "7rtPew9h1sMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create ALS model\n"
      ],
      "metadata": {
        "id": "URJ7P5q71sMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "als=ALS(maxIter=5,\n",
        "        regParam=0.09,\n",
        "        rank=25,\n",
        "        userCol=\"user_id_index\",\n",
        "        itemCol=\"business_id_index\",\n",
        "        ratingCol=\"stars\",\n",
        "        coldStartStrategy=\"drop\",\n",
        "        nonnegative=True)\n",
        "\n",
        "model=als.fit(training)"
      ],
      "metadata": {
        "trusted": true,
        "id": "SRNn37931sMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate RMSE"
      ],
      "metadata": {
        "id": "3rq8Lg9L1sMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"stars\",predictionCol=\"prediction\")\n",
        "predictions=model.transform(test)\n",
        "rmse=evaluator.evaluate(predictions)\n",
        "print(\"RMSE=\"+str(rmse))"
      ],
      "metadata": {
        "trusted": true,
        "id": "n0yjedn21sMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Recommendations\n",
        "\n"
      ],
      "metadata": {
        "id": "zCE_tAf01sMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = model.recommendForAllUsers(20).filter(col('user_id_index')==30).select(\"recommendations\").collect()\n",
        "topRestaurants = []\n",
        "for item in test[0][0]:\n",
        "    topRestaurants.append(item.business_id_index)\n",
        "\n",
        "schema = StructType([StructField(\"business_id_index\",IntegerType(),True)])\n",
        "restaurants = spark.createDataFrame(topRestaurants,IntegerType()).toDF(\"business_id_index\")\n",
        "\n",
        "\n",
        "transformed\\\n",
        ".select(['business_id', 'user_id', 'stars', 'categories'])\\\n",
        ".filter(col('user_id_index')==30)\\\n",
        ".show()\n",
        "\n",
        "restaurants\\\n",
        ".join(transformed, on = 'business_id_index', how = 'inner')\\\n",
        ".select(['business_id', 'stars', 'categories', 'name'])\\\n",
        ".drop_duplicates(subset=['name'])\\\n",
        ".show()\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "DktqkU-o1sMK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}